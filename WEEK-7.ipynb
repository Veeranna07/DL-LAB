{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BetsLxcN63m"
      },
      "source": [
        "**Implement mini batch optimization technique to improve the performance of deep learning model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0tL32Wpbtmwd"
      },
      "outputs": [],
      "source": [
        "# Import necessary Packages\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout, Flatten\n",
        "from keras.layers import Conv2D, GlobalMaxPool2D\n",
        "from keras import backend as K\n",
        "from keras.src import optimizers\n",
        "from keras.src.layers import MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HonlwhZGtvol",
        "outputId": "3b04f027-6ce4-4dcf-8787-9d795f5a74c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "(60000, 28, 28) (60000,)\n"
          ]
        }
      ],
      "source": [
        "# Load Dataset\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "print(x_train.shape , y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GiJELRxPtzrC"
      },
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0],28,28,1)\n",
        "x_test=x_test.reshape(x_test.shape[0],28,28,1)\n",
        "input_shape=(28,28,1)\n",
        "\n",
        "y_train=keras.utils.to_categorical(y_train)\n",
        "y_test=keras.utils.to_categorical(y_test)\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "batch_size=64\n",
        "num_classes =10\n",
        "epochs=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3kIAaM-st3Ye"
      },
      "outputs": [],
      "source": [
        "# Optimizer function\n",
        "\n",
        "def build_model(optimizer):\n",
        "  model=Sequential()\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCtV0GaHt7gL",
        "outputId": "9e081046-4a36-496f-8abc-b9d7970fbb4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with optimizer: Adadelta\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 2.2562 - accuracy: 0.1725 - val_loss: 2.1924 - val_accuracy: 0.3873\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 2.1601 - accuracy: 0.3219 - val_loss: 2.0843 - val_accuracy: 0.5966\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 2.0569 - accuracy: 0.4510 - val_loss: 1.9622 - val_accuracy: 0.6846\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.9385 - accuracy: 0.5432 - val_loss: 1.8253 - val_accuracy: 0.7327\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.8087 - accuracy: 0.6037 - val_loss: 1.6783 - val_accuracy: 0.7611\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.6725 - accuracy: 0.6417 - val_loss: 1.5283 - val_accuracy: 0.7803\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.5371 - accuracy: 0.6678 - val_loss: 1.3821 - val_accuracy: 0.7921\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 1.4073 - accuracy: 0.6889 - val_loss: 1.2470 - val_accuracy: 0.8022\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.2910 - accuracy: 0.7056 - val_loss: 1.1267 - val_accuracy: 0.8102\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 1.1869 - accuracy: 0.7200 - val_loss: 1.0215 - val_accuracy: 0.8202\n",
            "\n",
            "\n",
            "\n",
            "Training with optimizer: Adagrad\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 1.8369 - accuracy: 0.4735 - val_loss: 1.0275 - val_accuracy: 0.8226\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.8651 - accuracy: 0.7631 - val_loss: 0.5348 - val_accuracy: 0.8757\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.6226 - accuracy: 0.8179 - val_loss: 0.4218 - val_accuracy: 0.8928\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.5289 - accuracy: 0.8431 - val_loss: 0.3710 - val_accuracy: 0.9020\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.4826 - accuracy: 0.8569 - val_loss: 0.3407 - val_accuracy: 0.9083\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.4497 - accuracy: 0.8663 - val_loss: 0.3183 - val_accuracy: 0.9133\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.4226 - accuracy: 0.8734 - val_loss: 0.3025 - val_accuracy: 0.9170\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.4041 - accuracy: 0.8795 - val_loss: 0.2894 - val_accuracy: 0.9193\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3900 - accuracy: 0.8832 - val_loss: 0.2775 - val_accuracy: 0.9228\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.3737 - accuracy: 0.8885 - val_loss: 0.2672 - val_accuracy: 0.9249\n",
            "\n",
            "\n",
            "\n",
            "Training with optimizer: Adam\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 0.2421 - accuracy: 0.9260 - val_loss: 0.0724 - val_accuracy: 0.9764\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0979 - accuracy: 0.9704 - val_loss: 0.0472 - val_accuracy: 0.9839\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0711 - accuracy: 0.9787 - val_loss: 0.0420 - val_accuracy: 0.9852\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0562 - accuracy: 0.9827 - val_loss: 0.0428 - val_accuracy: 0.9857\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 0.0342 - val_accuracy: 0.9878\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 0.0339 - val_accuracy: 0.9883\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.0330 - val_accuracy: 0.9885\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 0.0346 - val_accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 0.0330 - val_accuracy: 0.9884\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.0296 - val_accuracy: 0.9903\n",
            "\n",
            "\n",
            "\n",
            "Training with optimizer: RMSprop\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 0.2313 - accuracy: 0.9298 - val_loss: 0.0783 - val_accuracy: 0.9744\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0903 - accuracy: 0.9728 - val_loss: 0.0501 - val_accuracy: 0.9824\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0680 - accuracy: 0.9795 - val_loss: 0.0438 - val_accuracy: 0.9855\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0584 - accuracy: 0.9820 - val_loss: 0.0423 - val_accuracy: 0.9859\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0515 - accuracy: 0.9841 - val_loss: 0.0389 - val_accuracy: 0.9861\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0478 - accuracy: 0.9857 - val_loss: 0.0367 - val_accuracy: 0.9883\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.0456 - val_accuracy: 0.9858\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0409 - accuracy: 0.9875 - val_loss: 0.0346 - val_accuracy: 0.9875\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.0336 - val_accuracy: 0.9888\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0362 - accuracy: 0.9886 - val_loss: 0.0357 - val_accuracy: 0.9877\n",
            "\n",
            "\n",
            "\n",
            "Training with optimizer: SGD\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.8177 - accuracy: 0.7518 - val_loss: 0.3006 - val_accuracy: 0.9169\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3866 - accuracy: 0.8834 - val_loss: 0.2262 - val_accuracy: 0.9343\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.3119 - accuracy: 0.9057 - val_loss: 0.1914 - val_accuracy: 0.9457\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2736 - accuracy: 0.9171 - val_loss: 0.1633 - val_accuracy: 0.9511\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2484 - accuracy: 0.9251 - val_loss: 0.1441 - val_accuracy: 0.9571\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2283 - accuracy: 0.9318 - val_loss: 0.1338 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.2080 - accuracy: 0.9379 - val_loss: 0.1265 - val_accuracy: 0.9629\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1986 - accuracy: 0.9400 - val_loss: 0.1148 - val_accuracy: 0.9658\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.1877 - accuracy: 0.9434 - val_loss: 0.1095 - val_accuracy: 0.9676\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1789 - accuracy: 0.9457 - val_loss: 0.1054 - val_accuracy: 0.9666\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Trying 5 Optimizers\n",
        "\n",
        "optimizers = ['Adadelta', 'Adagrad', 'Adam', 'RMSprop', 'SGD']\n",
        "\n",
        "for optimizer_name in optimizers:\n",
        "    print(f\"Training with optimizer: {optimizer_name}\")\n",
        "    model = build_model(optimizer_name)\n",
        "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "    print('\\n\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
